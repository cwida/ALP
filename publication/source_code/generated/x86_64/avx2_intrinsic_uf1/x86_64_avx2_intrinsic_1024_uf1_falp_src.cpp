#include "alp.hpp"
#include "fastlanes/macros.hpp"
#include <immintrin.h>

                    __m256d int64_to_double_fast_precise(const __m256i v)
                    /* Optimized full range int64_t to double conversion           */
                    /* Emulate _mm256_cvtepi64_pd()                                */
                    {
                        __m256i magic_i_lo   = _mm256_set1_epi64x(0x4330000000000000); /* 2^52               encoded as floating-point  */
                        __m256i magic_i_hi32 = _mm256_set1_epi64x(0x4530000080000000); /* 2^84 + 2^63        encoded as floating-point  */
                        __m256i magic_i_all  = _mm256_set1_epi64x(0x4530000080100000); /* 2^84 + 2^63 + 2^52 encoded as floating-point  */
                        __m256d magic_d_all  = _mm256_castsi256_pd(magic_i_all);
                    
                        __m256i v_lo =
                            _mm256_blend_epi32(magic_i_lo, v, 0b01010101); /* Blend the 32 lowest significant bits of v with magic_int_lo */
                        __m256i v_hi     = _mm256_srli_epi64(v, 32);       /* Extract the 32 most significant bits of v       */
                        v_hi             = _mm256_xor_si256(v_hi, magic_i_hi32); /* Flip the msb of v_hi and blend with 0x45300000 */
                        __m256d v_hi_dbl = _mm256_sub_pd(_mm256_castsi256_pd(v_hi), magic_d_all); /* Compute in double precision: */
                        __m256d result   = _mm256_add_pd(
                            v_hi_dbl,
                            _mm256_castsi256_pd(
                                v_lo)); /* (v_hi - magic_d_all) + v_lo  Do not assume associativity of floating point addition !! */
                        return result;    /* With gcc use -O3, then -fno-associative-math is default. Do not use -Ofast, which enables
                                             -fassociative-math! */
                    }
        
namespace generated
{
	namespace falp::x86_64
	{
		namespace avx2
		{
			static void falp_0bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), base_0);
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), base_0);
				}
			}
			static void falp_1bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_2bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_3bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_4bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_5bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_6bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_7bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_8bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_9bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_10bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_11bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_12bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_13bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_14bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_15bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_16bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_17bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_18bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_19bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,17), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 19) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_20bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_21bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 19) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,17), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 19) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,19), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 21) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_22bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_23bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 21) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,21), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 19) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,19), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 19) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,17), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 21) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 23) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_24bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_25bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,17), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 19) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 23) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,23), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 21) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 21) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,21), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 23) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 19) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,19), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 25) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_26bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_27bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 23) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,23), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 21) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 19) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,19), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 25) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 25) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,25), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 19) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 21) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,21), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 23) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,17), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 27) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_28bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_29bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 23) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 19) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,19), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 25) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,25), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 27) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 21) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 21) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,21), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 27) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,27), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 25) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 19) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,17), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 23) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,23), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 29) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_30bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_31bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 29) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 27) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 25) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 23) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 21) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 19) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,17), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 19) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,19), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 21) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,21), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 23) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,23), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 25) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,25), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 27) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,27), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 29) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,29), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 31) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_32bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_33bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 31) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,31), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 29) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,29), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 27) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,27), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 25) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,25), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 23) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,23), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 21) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,21), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 19) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,19), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,17), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 19) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 21) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 23) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 25) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 27) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 29) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 31) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 33) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_34bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_35bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 29) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,29), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 23) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,23), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,17), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 19) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 25) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 31) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 33) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,33), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 27) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,27), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 21) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,21), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 21) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 27) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 33) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 31) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,31), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 25) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,25), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 19) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,19), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 23) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 29) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 35) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_36bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_37bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 27) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,27), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,17), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 23) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 33) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 31) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,31), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 21) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,21), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 19) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 29) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 35) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,35), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 25) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,25), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 25) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 35) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 29) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,29), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 19) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,19), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 21) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 31) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 33) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,33), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 23) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,23), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 27) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 37) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_38bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_39bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 25) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,25), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 31) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 33) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,33), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 19) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,19), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 23) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 37) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 27) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,27), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 29) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 35) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,35), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 21) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,21), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 21) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 35) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 29) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,29), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 27) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 37) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,37), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 23) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,23), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 19) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 33) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 31) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,31), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,17), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 25) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 39) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_40bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_41bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 23) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,23), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 31) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 33) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,33), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 21) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 39) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 25) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,25), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 29) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 35) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,35), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,17), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 19) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 37) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 27) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,27), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 27) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 37) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,37), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 19) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,19), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 35) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 29) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,29), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 25) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 39) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,39), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 21) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,21), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 33) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 31) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,31), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 23) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 41) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_42bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 164);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 42) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_43bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 43) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 21) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,21), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 42) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,42), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 43) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 23) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 41) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,41), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 43) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 19) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,19), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 43) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 25) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 39) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,39), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 43) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,17), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 43) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 27) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 37) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,37), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 43) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 43) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 29) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 35) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,35), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 43) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 43) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 31) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 33) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,33), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 43) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 43) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 33) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 31) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,31), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 43) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 43) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 35) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 29) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,29), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 43) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 43) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 37) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 27) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,27), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 43) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 43) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 39) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 25) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,25), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 43) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 19) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 43) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 41) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 23) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,23), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 43) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 164);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 42) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 168);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 21) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 43) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_44bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 164);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 168);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 172);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_45bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 45) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 19) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,19), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 45) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 33) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 31) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,31), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 45) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 21) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 43) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,43), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 45) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,17), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 45) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 35) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 29) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,29), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 45) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 42) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 23) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 41) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,41), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 45) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 45) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 37) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 27) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,27), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 45) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 25) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 39) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,39), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 45) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 45) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 39) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 25) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,25), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 45) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 27) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 37) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,37), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 45) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 45) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 41) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 23) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,23), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 42) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,42), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 45) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 29) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 35) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,35), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 45) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 45) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 43) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 21) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,21), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 45) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 164);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 31) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 33) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 168);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,33), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 45) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 172);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 176);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 19) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 45) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_46bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 46) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 46) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 46) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 46) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 42) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,42), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 46) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 46) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 42) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 46) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 46) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 46) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 46) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 46) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 46) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 46) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 46) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 42) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,42), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 46) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 46) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 42) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 46) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 46) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 164);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 168);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 172);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 46) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 176);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 180);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 46) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_47bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 47) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,17), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 47) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 43) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 21) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,21), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 47) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 39) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 25) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,25), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 42) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,42), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 47) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 35) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 29) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,29), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 46) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,46), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 47) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 31) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 33) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,33), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 47) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 27) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 37) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,37), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 47) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 23) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 41) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,41), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 47) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 19) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 45) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,45), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 47) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 47) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 45) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 19) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,19), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 47) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 41) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 23) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,23), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 47) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 37) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 27) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,27), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 47) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 33) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 31) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,31), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 47) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 46) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 29) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 35) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,35), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 47) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 42) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 25) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 39) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 164);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,39), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 47) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 168);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 172);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 21) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 43) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 176);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,43), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 47) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 180);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 184);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 47) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_48bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 164);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 168);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 172);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 176);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 180);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 184);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 188);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_49bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 49) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 19) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 45) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,45), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 49) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 23) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 41) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,41), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 49) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 42) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 27) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 37) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,37), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 49) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 46) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 31) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 33) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,33), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 49) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 35) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 29) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,29), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 49) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 39) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 25) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,25), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 49) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 43) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 21) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,21), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 49) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 47) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,17), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 47) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,47), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 49) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 21) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 43) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,43), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 49) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 25) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 39) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,39), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 49) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 29) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 35) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,35), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 49) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 33) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 31) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,31), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 46) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,46), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 49) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 37) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 27) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 164);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,27), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 42) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 168);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,42), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 49) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 172);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 41) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 23) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 176);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,23), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 180);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 49) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 184);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 45) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 19) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 188);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,19), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 192);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 49) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_50bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 50) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 42) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,42), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 50) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 50) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 50) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 46) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 46) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,46), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 50) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 50) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 50) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 42) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 50) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 50) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 42) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,42), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 50) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 50) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 50) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 46) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 46) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,46), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 50) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 164);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 168);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 50) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 172);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 176);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 180);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 184);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 50) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 188);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 42) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 192);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 196);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 50) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_51bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 51) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 25) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 39) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,39), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 51) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 50) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 37) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 27) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,27), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 51) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 49) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 23) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 41) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,41), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 51) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 35) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 29) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,29), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 42) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,42), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 51) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 47) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,17), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 21) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 43) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,43), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 51) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 46) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 33) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 31) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,31), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 51) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 45) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 19) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,19), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 19) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 45) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,45), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 51) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 31) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 33) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,33), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 46) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,46), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 51) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 43) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 21) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,21), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 47) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,47), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 51) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 42) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 29) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 35) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,35), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 51) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 41) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 23) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 164);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,23), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 168);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 49) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 172);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,49), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 51) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 176);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 180);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 27) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 37) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 184);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,37), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 50) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 188);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,50), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 51) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 192);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 39) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 25) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 196);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,25), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 200);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 51) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_52bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 52) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 52) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 52) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 52) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 52) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 52) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 52) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 52) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 52) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 52) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 52) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 52) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 52) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 164);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 168);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 172);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 52) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 176);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 180);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 184);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 188);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 52) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 192);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 196);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 200);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 204);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 52) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_53bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 53) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 42) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 31) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 33) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,33), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 53) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 51) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 29) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 35) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,35), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 46) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,46), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 53) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 49) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 27) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 37) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,37), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 53) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 47) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,17), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 25) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 39) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,39), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 50) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,50), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 53) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 45) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 19) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,19), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 23) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 41) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,41), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 52) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,52), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 53) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 43) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 21) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,21), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 21) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 43) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,43), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 53) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 52) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 41) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 23) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,23), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 19) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 45) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,45), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 53) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 50) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 39) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 25) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,25), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 47) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,47), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 53) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 37) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 27) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 164);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,27), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 168);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 49) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 172);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,49), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 53) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 176);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 46) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 180);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 35) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 29) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 184);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,29), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 188);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 51) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 192);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,51), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 53) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 196);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 200);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 33) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 31) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 204);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,31), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 42) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 208);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,42), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 53) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_54bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 54) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 50) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,50), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 54) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 46) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,46), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 54) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 52) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 42) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 42) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,42), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 52) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,52), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 54) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 46) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 54) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 50) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 54) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 54) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 50) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,50), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 54) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 46) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,46), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 54) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 52) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 42) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 164);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 42) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 168);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,42), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 52) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 172);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,52), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 54) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 176);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 46) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 180);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 184);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 188);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 192);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 54) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 196);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 50) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 200);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 204);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 208);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 212);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 54) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_55bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 55) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 46) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 37) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 27) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,27), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 19) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 45) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,45), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 54) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,54), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 55) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 47) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,17), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 29) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 35) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,35), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 53) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,53), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 55) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 39) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 25) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,25), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 21) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 43) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,43), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 52) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,52), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 55) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 49) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 31) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 33) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,33), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 42) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,42), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 51) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,51), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 55) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 50) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 41) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 23) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,23), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 23) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 41) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,41), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 50) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,50), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 55) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 51) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 42) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 33) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 31) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,31), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 49) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,49), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 55) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 52) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 43) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 21) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,21), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 25) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 39) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 164);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,39), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 168);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 55) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 172);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 53) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 176);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 180);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 35) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 29) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 184);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,29), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 188);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 47) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 192);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,47), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 55) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 196);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 54) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 200);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 45) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 19) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 204);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,19), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 208);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 27) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 37) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 212);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,37), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 46) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 216);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,46), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 55) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_56bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 56) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 56) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 56) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 56) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 56) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 56) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 56) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 56) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 56) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 56) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 56) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 164);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 56) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 168);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 56) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 172);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 176);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 180);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 184);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 188);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 192);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 56) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 196);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 56) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 200);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 204);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 208);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 212);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 216);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 220);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 56) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_57bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 57) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 50) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 43) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 21) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,21), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 29) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 35) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,35), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 42) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,42), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 49) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,49), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 56) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,56), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 57) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 51) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 37) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 27) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,27), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 23) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 41) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,41), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 55) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,55), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 57) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 52) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 45) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 19) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,19), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 31) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 33) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,33), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 47) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,47), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 54) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,54), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 57) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 53) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 46) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 39) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 25) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,25), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 25) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 39) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,39), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 46) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,46), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 53) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,53), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 57) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 54) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 47) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,17), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 33) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 31) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,31), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 19) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 45) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,45), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 52) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,52), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 57) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 164);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 55) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 168);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 172);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 41) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 23) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 176);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,23), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 180);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 27) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 37) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 184);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,37), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 188);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 51) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 192);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,51), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 57) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 196);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 56) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 200);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 49) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 204);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 42) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 208);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 35) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 29) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 212);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,29), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 216);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 21) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 43) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 220);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,43), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 50) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 224);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,50), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 57) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_58bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 58) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 52) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 46) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 42) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,42), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 54) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,54), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 58) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 56) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 50) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 50) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,50), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 56) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,56), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 58) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 54) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 42) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 46) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,46), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 52) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,52), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 58) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 58) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 52) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 46) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 42) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,42), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 54) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,54), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 58) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 56) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 50) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 164);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 168);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 172);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 176);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 180);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 184);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 50) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 188);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,50), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 56) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 192);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,56), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 58) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 196);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 54) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 200);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 204);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 42) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 208);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 212);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 216);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 220);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 46) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 224);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,46), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 52) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 228);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,52), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 58) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_59bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 59) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 54) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 49) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 39) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 25) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,25), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 29) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 35) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,35), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 19) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 45) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,45), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 50) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,50), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 55) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,55), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 59) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 58) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 53) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 43) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 21) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,21), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 33) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 31) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,31), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 23) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 41) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,41), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 46) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,46), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 51) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,51), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 56) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,56), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 59) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 57) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 52) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 47) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 42) - 1)) ,17), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 37) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 27) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,27), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 27) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 37) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,37), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 42) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1)) ,42), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 47) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,47), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 52) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,52), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 57) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,57), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 59) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 56) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 51) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 46) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 41) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 23) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,23), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 164);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 31) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 33) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 168);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,33), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 172);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 21) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 43) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 176);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,43), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 180);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 53) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 184);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,53), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 58) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 188);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,58), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 59) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 192);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 55) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 196);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 50) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 200);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 45) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 19) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 204);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,19), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 208);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 35) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 29) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 212);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,29), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 216);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 25) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 39) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 220);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,39), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 224);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 49) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 228);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,49), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 54) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 232);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,54), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 59) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_60bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 60) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 56) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 52) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 52) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,52), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 56) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,56), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 60) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 60) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 56) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 52) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 52) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,52), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 56) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,56), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 60) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 60) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 56) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 52) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 164);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 168);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 52) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 172);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,52), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 56) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 176);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,56), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 60) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 180);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 60) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 184);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 56) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 188);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 52) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 192);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 196);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 200);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 204);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 208);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 212);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 216);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 220);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 224);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 228);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 52) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 232);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,52), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 56) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 236);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,56), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 60) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_61bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 61) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 58) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 55) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 52) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 49) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 46) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 43) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 21) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,21), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 37) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 27) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,27), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 31) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 33) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,33), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 25) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 39) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,39), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 42) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 19) - 1)) ,42), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 45) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,45), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 51) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,51), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 54) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,54), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 57) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,57), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 60) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,60), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 61) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 59) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 56) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 53) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 50) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 47) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,17), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 41) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 23) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,23), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 35) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 29) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,29), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 29) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 35) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,35), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 23) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 41) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,41), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 47) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,47), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 50) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,50), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 53) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,53), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 56) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,56), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 59) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,59), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 61) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 164);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 60) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 168);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 57) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 172);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 54) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 176);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 51) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 180);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 184);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 45) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 19) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 188);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 42) - 1)) ,19), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 192);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 39) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 25) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 196);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,25), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 200);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 33) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 31) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 204);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,31), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 208);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 27) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 37) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 212);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,37), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 216);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 21) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 43) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 220);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,43), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 46) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 224);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,46), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 49) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 228);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,49), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 52) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 232);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,52), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 55) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 236);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,55), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 58) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 240);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,58), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 61) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_62bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 62) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 60) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 58) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 56) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 54) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 52) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 50) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 46) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 42) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 42) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,42), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 46) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,46), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 50) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,50), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 52) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,52), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 54) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,54), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 56) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,56), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 58) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,58), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 60) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,60), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 62) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 62) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 60) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 58) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 56) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 54) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 52) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 50) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 46) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 164);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 42) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 168);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 172);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 176);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 180);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 184);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 188);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 192);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 196);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 200);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 204);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 42) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 208);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,42), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 212);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 46) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 216);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,46), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 220);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 50) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 224);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,50), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 52) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 228);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,52), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 54) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 232);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,54), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 56) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 236);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,56), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 58) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 240);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,58), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 60) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 244);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,60), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 62) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_63bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					tmp_0 = _mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 63) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 63), _mm256_set1_epi64((1ULL << 1) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 62) - 1)) ,1), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 62), _mm256_set1_epi64((1ULL << 2) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 61) - 1)) ,2), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 61), _mm256_set1_epi64((1ULL << 3) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 60) - 1)) ,3), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 60), _mm256_set1_epi64((1ULL << 4) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 59) - 1)) ,4), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 59), _mm256_set1_epi64((1ULL << 5) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 58) - 1)) ,5), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 58), _mm256_set1_epi64((1ULL << 6) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 57) - 1)) ,6), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 57), _mm256_set1_epi64((1ULL << 7) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 56) - 1)) ,7), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 56), _mm256_set1_epi64((1ULL << 8) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 55) - 1)) ,8), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 55), _mm256_set1_epi64((1ULL << 9) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 54) - 1)) ,9), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 54), _mm256_set1_epi64((1ULL << 10) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 53) - 1)) ,10), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 53), _mm256_set1_epi64((1ULL << 11) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 52) - 1)) ,11), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 52), _mm256_set1_epi64((1ULL << 12) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 51) - 1)) ,12), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 51), _mm256_set1_epi64((1ULL << 13) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 50) - 1)) ,13), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 50), _mm256_set1_epi64((1ULL << 14) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 49) - 1)) ,14), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 49), _mm256_set1_epi64((1ULL << 15) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 48) - 1)) ,15), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 48), _mm256_set1_epi64((1ULL << 16) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 47) - 1)) ,16), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 47), _mm256_set1_epi64((1ULL << 17) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 46) - 1)) ,17), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 46), _mm256_set1_epi64((1ULL << 18) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 45) - 1)) ,18), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 45), _mm256_set1_epi64((1ULL << 19) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 44) - 1)) ,19), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 44), _mm256_set1_epi64((1ULL << 20) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 43) - 1)) ,20), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 43), _mm256_set1_epi64((1ULL << 21) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 42) - 1)) ,21), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 42), _mm256_set1_epi64((1ULL << 22) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 41) - 1)) ,22), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 41), _mm256_set1_epi64((1ULL << 23) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 40) - 1)) ,23), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 40), _mm256_set1_epi64((1ULL << 24) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 39) - 1)) ,24), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 39), _mm256_set1_epi64((1ULL << 25) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 38) - 1)) ,25), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 38), _mm256_set1_epi64((1ULL << 26) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 37) - 1)) ,26), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 37), _mm256_set1_epi64((1ULL << 27) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 36) - 1)) ,27), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 36), _mm256_set1_epi64((1ULL << 28) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 35) - 1)) ,28), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 35), _mm256_set1_epi64((1ULL << 29) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 34) - 1)) ,29), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 34), _mm256_set1_epi64((1ULL << 30) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 33) - 1)) ,30), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 33), _mm256_set1_epi64((1ULL << 31) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 32) - 1)) ,31), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 32), _mm256_set1_epi64((1ULL << 32) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 31) - 1)) ,32), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 31), _mm256_set1_epi64((1ULL << 33) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 30) - 1)) ,33), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 30), _mm256_set1_epi64((1ULL << 34) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 29) - 1)) ,34), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 29), _mm256_set1_epi64((1ULL << 35) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 28) - 1)) ,35), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 28), _mm256_set1_epi64((1ULL << 36) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 27) - 1)) ,36), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 27), _mm256_set1_epi64((1ULL << 37) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 26) - 1)) ,37), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 26), _mm256_set1_epi64((1ULL << 38) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 25) - 1)) ,38), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 25), _mm256_set1_epi64((1ULL << 39) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 24) - 1)) ,39), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 24), _mm256_set1_epi64((1ULL << 40) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 23) - 1)) ,40), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 23), _mm256_set1_epi64((1ULL << 41) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 164);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 22) - 1)) ,41), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 22), _mm256_set1_epi64((1ULL << 42) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 168);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 21) - 1)) ,42), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 21), _mm256_set1_epi64((1ULL << 43) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 172);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 20) - 1)) ,43), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 20), _mm256_set1_epi64((1ULL << 44) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 176);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 19) - 1)) ,44), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 19), _mm256_set1_epi64((1ULL << 45) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 180);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 18) - 1)) ,45), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 18), _mm256_set1_epi64((1ULL << 46) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 184);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 17) - 1)) ,46), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 17), _mm256_set1_epi64((1ULL << 47) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 188);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 16) - 1)) ,47), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 16), _mm256_set1_epi64((1ULL << 48) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 192);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 15) - 1)) ,48), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 15), _mm256_set1_epi64((1ULL << 49) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 196);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 14) - 1)) ,49), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 14), _mm256_set1_epi64((1ULL << 50) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 200);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 13) - 1)) ,50), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 13), _mm256_set1_epi64((1ULL << 51) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 204);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 12) - 1)) ,51), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 12), _mm256_set1_epi64((1ULL << 52) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 208);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 11) - 1)) ,52), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 11), _mm256_set1_epi64((1ULL << 53) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 212);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 10) - 1)) ,53), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 10), _mm256_set1_epi64((1ULL << 54) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 216);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 9) - 1)) ,54), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 9), _mm256_set1_epi64((1ULL << 55) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 220);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 8) - 1)) ,55), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 8), _mm256_set1_epi64((1ULL << 56) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 224);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 7) - 1)) ,56), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 7), _mm256_set1_epi64((1ULL << 57) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 228);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 6) - 1)) ,57), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 6), _mm256_set1_epi64((1ULL << 58) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 232);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 5) - 1)) ,58), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 5), _mm256_set1_epi64((1ULL << 59) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 236);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 4) - 1)) ,59), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 4), _mm256_set1_epi64((1ULL << 60) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 240);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 3) - 1)) ,60), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 3), _mm256_set1_epi64((1ULL << 61) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 244);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 2) - 1)) ,61), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 2), _mm256_set1_epi64((1ULL << 62) - 1));
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 248);
					tmp_0 = _mm256_or_si256(_mm256_slli_epi64(_mm256_and_si256(register_0, _mm256_set1_epi64((1ULL << 1) - 1)) ,62), tmp_0);
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), tmp_dbl);
					tmp_0 = _mm256_and_si256(_mm256_srli_epi64(register_0, 1), _mm256_set1_epi64((1ULL << 63) - 1));
					tmp_0 += base_0;
					tmp_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					tmp_dbl *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), tmp_dbl);
				}
			}
			static void falp_64bw_64ow_256crw_1uf(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				[[maybe_unused]] auto out = reinterpret_cast<__m256i *>(a_out_p);
				[[maybe_unused]] const auto in = reinterpret_cast<const __m256i *>(a_in_p);
				[[maybe_unused]] __m256i register_0;
				[[maybe_unused]] __m256i tmp_0;
				[[maybe_unused]] __m256i base_0 = _mm256_set1_epi64(*(a_base_p));
				[[maybe_unused]] __m256i factor = _mm256_set1_epi64(alp::Constants<double>::FACT_ARR[fac]);
				[[maybe_unused]] __m256d frac10 = _mm256_set1_pd(alp::Constants<double>::FRAC_ARR[exp]);
				[[maybe_unused]] __m256d tmp_dbl;
				for (int i = 0; i < 4; ++i)
				{
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 0);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 0), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 4);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 1), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 8);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 2), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 12);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 3), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 16);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 4), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 20);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 5), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 24);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 6), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 28);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 7), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 32);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 8), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 36);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 9), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 40);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 10), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 44);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 11), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 48);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 12), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 52);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 13), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 56);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 14), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 60);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 15), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 64);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 16), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 68);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 17), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 72);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 18), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 76);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 19), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 80);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 20), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 84);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 21), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 88);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 22), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 92);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 23), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 96);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 24), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 100);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 25), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 104);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 26), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 108);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 27), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 112);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 28), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 116);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 29), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 120);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 30), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 124);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 31), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 128);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 32), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 132);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 33), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 136);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 34), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 140);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 35), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 144);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 36), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 148);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 37), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 152);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 38), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 156);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 39), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 160);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 40), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 164);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 41), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 168);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 42), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 172);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 43), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 176);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 44), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 180);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 45), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 184);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 46), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 188);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 47), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 192);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 48), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 196);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 49), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 200);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 50), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 204);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 51), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 208);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 52), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 212);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 53), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 216);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 54), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 220);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 55), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 224);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 56), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 228);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 57), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 232);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 58), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 236);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 59), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 240);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 60), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 244);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 61), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 248);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 62), register_0);
					register_0 = _mm256_loadu_si256(in + (0 * 4) + (i * 1) + 252);
					register_0 += base_0;
					register_0 *= factor;
					tmp_dbl = int64_to_double_fast_precise(tmp_0);
					register_0 *= frac10;
					_mm256_storeu_si256(out + (i * 1) + (0 * 4) + (4 * 63), register_0);
				}
			}
			void falp(const uint64_t *__restrict a_in_p, double *__restrict a_out_p, uint8_t bw, const uint64_t *__restrict a_base_p, uint8_t fac, uint8_t exp)
			{
				 switch (bw)
				{
					case 0:
					   falp_0bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 1:
					   falp_1bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 2:
					   falp_2bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 3:
					   falp_3bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 4:
					   falp_4bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 5:
					   falp_5bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 6:
					   falp_6bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 7:
					   falp_7bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 8:
					   falp_8bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 9:
					   falp_9bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 10:
					   falp_10bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 11:
					   falp_11bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 12:
					   falp_12bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 13:
					   falp_13bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 14:
					   falp_14bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 15:
					   falp_15bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 16:
					   falp_16bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 17:
					   falp_17bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 18:
					   falp_18bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 19:
					   falp_19bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 20:
					   falp_20bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 21:
					   falp_21bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 22:
					   falp_22bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 23:
					   falp_23bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 24:
					   falp_24bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 25:
					   falp_25bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 26:
					   falp_26bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 27:
					   falp_27bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 28:
					   falp_28bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 29:
					   falp_29bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 30:
					   falp_30bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 31:
					   falp_31bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 32:
					   falp_32bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 33:
					   falp_33bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 34:
					   falp_34bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 35:
					   falp_35bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 36:
					   falp_36bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 37:
					   falp_37bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 38:
					   falp_38bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 39:
					   falp_39bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 40:
					   falp_40bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 41:
					   falp_41bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 42:
					   falp_42bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 43:
					   falp_43bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 44:
					   falp_44bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 45:
					   falp_45bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 46:
					   falp_46bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 47:
					   falp_47bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 48:
					   falp_48bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 49:
					   falp_49bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 50:
					   falp_50bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 51:
					   falp_51bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 52:
					   falp_52bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 53:
					   falp_53bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 54:
					   falp_54bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 55:
					   falp_55bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 56:
					   falp_56bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 57:
					   falp_57bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 58:
					   falp_58bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 59:
					   falp_59bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 60:
					   falp_60bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 61:
					   falp_61bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 62:
					   falp_62bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 63:
					   falp_63bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
					case 64:
					   falp_64bw_64ow_256crw_1uf(a_in_p, a_out_p, a_base_p, fac, exp);
					   break;
				}
			}
		}
	}
}
;
